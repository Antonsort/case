{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"data_revised.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of customers already investing:  3316\n",
      "No of potential investors:  7135\n"
     ]
    }
   ],
   "source": [
    "#Lets start by defining prediction problem: Identifying customers that are going to invest.\n",
    "#This means among customers who are not already investing, who is mostly likely to invest.\n",
    "#To Reduce scope, we can sort out customers who where investing at the start 2022 (the year of our data). \n",
    "#If I had more historical data, all customers would potentially be eligible. But since \"investing for the first time\" is a one time event for all customers\n",
    "#We sort out customers out as soon as they have invested something. \n",
    "#Lets start by defining already invested customers to sort them out. \n",
    "#Normally I would define already invested customers as customers having Investment_Assets>0 at any time t-n, where n=>0. But since we dont have unlimited history,\n",
    "#I define it as Investment_Assets>0 in the first month of 2022 or if the customers are new in 2022, their first month.\n",
    "\n",
    "#Reduce dataset to include only the first observation of every customer\n",
    "\n",
    "df = df.copy()\n",
    "df['FactDt'] = pd.to_datetime(df['FactDt'])\n",
    "\n",
    "df_first_obs = (\n",
    "    df.sort_values(['Customer_number', 'FactDt'])\n",
    "      .drop_duplicates(subset=['Customer_number'], keep='first')\n",
    "      .copy()\n",
    ")\n",
    "\n",
    "df_first_obs.loc[((df_first_obs['Investment_Assets']>0)|(df_first_obs['AvgInvestmentsValueDKK']>0)), \"Already_invested\"]=True\n",
    "\n",
    "print('No of customers already investing: ', df_first_obs['Already_invested'].sum())\n",
    "\n",
    "#Sort out those customers (pi=potential investors)\n",
    "df_pi = df.loc[~df['Customer_number'].isin(df_first_obs.loc[df_first_obs['Already_invested']==True, 'Customer_number'])]\n",
    "\n",
    "print('No of potential investors: ', df_pi['Customer_number'].nunique())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No of potential investors:  6252\n"
     ]
    }
   ],
   "source": [
    "#Next i also want to reduced the potential investors, by sorting out \"kids\" - it seems unethical to do any investing marketing towards them + the marketing if it were should be targeting the parents to invest \"Børneopsparingen\". \n",
    "# So i reduce the scope to customers above 16 years old:\n",
    "df_pi = df_pi.loc[df_pi['CustAgeInYears']>16]\n",
    "\n",
    "print('No of potential investors: ', df_pi['Customer_number'].nunique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First-time invest events: 93\n"
     ]
    }
   ],
   "source": [
    "# Define target: first-time invest event\n",
    "df_pi = df_pi.sort_values(['Customer_number', 'FactDt']).copy()\n",
    "\n",
    "# Invested at time t (using Investment_Assets)\n",
    "invested_t = df_pi['Investment_Assets'] > 0\n",
    "\n",
    "# Had invested at any previous time t-n, n>0\n",
    "had_invested_before = invested_t.groupby(df_pi['Customer_number']).cummax().groupby(df_pi['Customer_number']).shift(fill_value=False)\n",
    "\n",
    "# First-time invest: invested now, but never invested before\n",
    "df_pi['first_time_invest'] = invested_t & (~had_invested_before)\n",
    "\n",
    "print('First-time invest events:', int(df_pi['first_time_invest'].sum()))\n",
    "\n",
    "#I want the flag moved up one time (so the predvious month is flagged as first time investors. Cause it is these once I want to predict - just before they actaully invest)\n",
    "#But also to prevent any data leakage.\n",
    "\n",
    "df_pi['first_time_invest']=df_pi['first_time_invest'].shift(-1)\n",
    "\n",
    "#Now we can sort out all the months where investment_assets>0\n",
    "\n",
    "df_pi=df_pi.loc[df_pi['Investment_Assets']==0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Its time to define the prediction problem even more. Now there is two possible ways to go with it, either is a binary classification problem, where we just want to predict is this a possible first time investor?\n",
    "#Or as a time to event problem, where we predict and rank customers in orders of who has the least predicted time to event. However in this case, which so \"few history\", and not a lot of data, this will probably not work on this case. \n",
    "#But I will give it a try later. \n",
    "#But lets start by doing it is a binary classification problem. And I define \"first time invest\" customers as customer who gonna invest within the following year. Since we only have year of data, all customers with \"first_time_invest\" flag will be considered with a target 1 variable\n",
    "\n",
    "\n",
    "future_investors = set(df_pi.loc[df_pi['first_time_invest'].fillna(False), 'Customer_number'])\n",
    "df_pi['BI_Label'] = df_pi['Customer_number'].isin(future_investors).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_number</th>\n",
       "      <th>FactDt</th>\n",
       "      <th>first_time_invest</th>\n",
       "      <th>event_observed</th>\n",
       "      <th>TTE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000022D8D733FA51200BF5F45C37AED2</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000022D8D733FA51200BF5F45C37AED2</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000022D8D733FA51200BF5F45C37AED2</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000022D8D733FA51200BF5F45C37AED2</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000022D8D733FA51200BF5F45C37AED2</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>False</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    Customer_number     FactDt first_time_invest  \\\n",
       "0  000022D8D733FA51200BF5F45C37AED2 2022-01-31             False   \n",
       "1  000022D8D733FA51200BF5F45C37AED2 2022-02-28             False   \n",
       "2  000022D8D733FA51200BF5F45C37AED2 2022-03-31             False   \n",
       "3  000022D8D733FA51200BF5F45C37AED2 2022-04-30             False   \n",
       "4  000022D8D733FA51200BF5F45C37AED2 2022-05-31             False   \n",
       "\n",
       "   event_observed   TTE  \n",
       "0               0  13.0  \n",
       "1               0  12.0  \n",
       "2               0  11.0  \n",
       "3               0  10.0  \n",
       "4               0   9.0  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "#Lets also define target variable if we were to handle the problem as a time to event. Since we have time in months our time to event is gonna be in months.\n",
    "# Row-based TTE target with censoring at Jan 2023\n",
    "df_pi = df_pi.sort_values(['Customer_number', 'FactDt']).copy()\n",
    "df_pi['FactDt'] = pd.to_datetime(df_pi['FactDt'])\n",
    "\n",
    "today_ref = pd.Timestamp('2023-01-31')  # pretend \"today\"\n",
    "\n",
    "def add_tte_row_event(group):\n",
    "    group = group.sort_values('FactDt').copy().reset_index(drop=True)\n",
    "    event_mask = group['first_time_invest'].fillna(False).astype(bool).to_numpy()\n",
    "    event_pos = np.where(event_mask)[0]\n",
    "\n",
    "    if len(event_pos) > 0:\n",
    "        # Use first observed event\n",
    "        e = event_pos[0]\n",
    "        group['TTE'] = (e - np.arange(len(group)) + 1).astype(float)  # event row = 1\n",
    "        # optional: remove rows after event\n",
    "        group.loc[np.arange(len(group)) > e, 'TTE'] = np.nan\n",
    "        group['event_observed'] = 1\n",
    "    else:\n",
    "        # No event: censored at Jan 2023 (calendar-month distance, starts at 1)\n",
    "        group['TTE'] = (\n",
    "            (today_ref.year - group['FactDt'].dt.year) * 12\n",
    "            + (today_ref.month - group['FactDt'].dt.month)\n",
    "            + 1\n",
    "        ).astype(float)\n",
    "        group['TTE'] = group['TTE'].clip(lower=1)\n",
    "        group['event_observed'] = 0\n",
    "\n",
    "    return group\n",
    "\n",
    "df_pi = (\n",
    "    df_pi.groupby('Customer_number', group_keys=False)\n",
    "         .apply(add_tte_row_event)\n",
    ")\n",
    "\n",
    "# quick check\n",
    "df_pi[['Customer_number', 'FactDt', 'first_time_invest', 'event_observed', 'TTE']].head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now that actually have defined the prediction problems, we are gonna do some nice feature engineering. Now most obvious is to start by converting all \"stamdata\" features to something useful, and do some feature engineering to capture time trends in the data\n",
    "\n",
    "#calculate seniority in years as time difference between CustEstbDt and FactDt\n",
    "df_pi['CustEstbDt'] = pd.to_datetime(df_pi['CustEstbDt'], errors='coerce')\n",
    "df_pi['anc_y'] = (df_pi['FactDt'] - df_pi['CustEstbDt']).dt.days / 365.25\n",
    "\n",
    "#drop column CustEstbDt\n",
    "df_pi = df_pi.drop(columns=['CustEstbDt'])\n",
    "\n",
    "#Convert CustGenderCd to dummy variable\n",
    "df_pi = pd.get_dummies(df_pi, columns=['CustGenderCd'], drop_first=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate trend features for BusinessVolumeDKK, Net_wealth and Financial Assets. I want both the change from this moth to last month, but also the trend over the last 6 months. I want the monthly change in percentage.\n",
    "\n",
    "def rolling_slope(values):\n",
    "    y = pd.Series(values).astype(float)\n",
    "    x = np.arange(len(y), dtype=float)\n",
    "    mask = y.notna()\n",
    "    if mask.sum() < 2:\n",
    "        return np.nan\n",
    "    return np.polyfit(x[mask], y[mask], 1)[0]\n",
    "\n",
    "for col in ['Business_Volume', 'Net_Wealth', 'Financial_Assets']:\n",
    "    # month-to-month % change\n",
    "    df_pi[f'{col}_change_pct'] = df_pi.groupby('Customer_number')[col].pct_change() * 100\n",
    "\n",
    "    # rolling 4m trend as % per month:\n",
    "    # slope on log1p(level) -> convert back to % growth per month\n",
    "    log_col = np.log1p(df_pi[col].clip(lower=0))\n",
    "    slope_log = (\n",
    "        log_col.groupby(df_pi['Customer_number'])\n",
    "               .transform(lambda s: s.rolling(window=4, min_periods=2).apply(rolling_slope, raw=True))\n",
    "    )\n",
    "    df_pi[f'{col}_trend_4m'] = (np.expm1(slope_log) * 100)\n",
    "    df_pi[f'{col}_change'] = df_pi.groupby('Customer_number')[col].pct_change()\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate trend in in number of times visiting website and app:\n",
    "\n",
    "for col in ['CustMobileLogOnPerMth', 'CustNetBankLogOnPerMth']:\n",
    "    g = df_pi.groupby('Customer_number')[col]\n",
    "\n",
    "    # 1-month absolute difference\n",
    "    df_pi[f'{col}_diff_1m'] = g.diff(1)\n",
    "\n",
    "    # Mean of the last 4 monthly absolute differences\n",
    "    df_pi[f'{col}_diff_4m_mean'] = (\n",
    "        df_pi.groupby('Customer_number')[f'{col}_diff_1m']\n",
    "             .transform(lambda s: s.rolling(window=4, min_periods=1).mean())\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lastly thinking about what other values could indicate a shift in life. In segmentation we noticed different depending on adult family members and children. So maybe we can also capture changes in the number of adult family members and children in the household as features.\n",
    "#capture changes in fam_members as two variables, (one as the latest change (has it gone down or up)) and one as the month since the last change (in the last 6 months)\n",
    "#doing it for fam_members will captue both adult changes and children changes since we will still use how many adult and family members there is\n",
    "\n",
    "col = 'fam_members'  # change name if your column differs\n",
    "\n",
    "df_pi = df_pi.sort_values(['Customer_number', 'FactDt']).copy()\n",
    "\n",
    "# 1) Latest change (up/down/same)\n",
    "df_pi[f'{col}_diff_1m'] = df_pi.groupby('Customer_number')[col].diff(1)\n",
    "df_pi[f'{col}_change_dir'] = np.sign(df_pi[f'{col}_diff_1m']).astype('float')\n",
    "# interpretation: -1 = down, 0 = no change, 1 = up\n",
    "\n",
    "# 2) Months since last change (looking back max 4 months)\n",
    "changed = df_pi[f'{col}_diff_1m'].fillna(0).ne(0)\n",
    "\n",
    "def months_since_last_change(flag_series):\n",
    "    idx = np.arange(len(flag_series), dtype=float)\n",
    "    last_change_idx = np.where(flag_series.values, idx, np.nan)\n",
    "    last_change_idx = pd.Series(last_change_idx).ffill().to_numpy()\n",
    "    out = idx - last_change_idx\n",
    "    out[np.isnan(last_change_idx)] = 0\n",
    "    return pd.Series(out, index=flag_series.index)\n",
    "\n",
    "df_pi[f'{col}_months_since_change'] = (\n",
    "    changed.groupby(df_pi['Customer_number'], group_keys=False)\n",
    "           .apply(months_since_last_change)\n",
    ")\n",
    "\n",
    "# Keep only \"in last 6 months\" (else NaN)\n",
    "df_pi.loc[df_pi[f'{col}_months_since_change'] > 4, f'{col}_months_since_change'] = 0 #max time\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Lastly to test if features like \"take up a house loan in the last 4 months\" or \"car loan in the last 4 months\" could be useful, since these are big life events that could trigger investing.\n",
    "#I will do it for both house loan and car loan, and I will capture it as\n",
    "#1) a binary variable indicating if they have taken up the loan in the last 4 months\n",
    "#2) a variable indicating how many months since they took up the loan (capped at 4 months, else 4) (similar to the fam_members change above)\n",
    "\n",
    "for loan_col in ['HomeLoan', 'CAR_LOANS']:  \n",
    "    # 1) Binary variable for taking up the loan in the last 4 months\n",
    "    df_pi[f'{loan_col}_taken_4m'] = (\n",
    "        df_pi.groupby('Customer_number')[loan_col]\n",
    "             .transform(lambda s: s.rolling(window=4, min_periods=1).max())\n",
    "    )\n",
    "\n",
    "    # 2) Months since took up the loan (capped at 4)\n",
    "    taken = df_pi[loan_col].fillna(0).astype(bool)\n",
    "\n",
    "    def months_since_taken(flag_series):\n",
    "        idx = np.arange(len(flag_series), dtype=float)\n",
    "        last_taken_idx = np.where(flag_series.values, idx, np.nan)\n",
    "        last_taken_idx = pd.Series(last_taken_idx).ffill().to_numpy()\n",
    "        out = idx - last_taken_idx\n",
    "        out[np.isnan(last_taken_idx)] = 0\n",
    "        return pd.Series(out, index=flag_series.index)\n",
    "\n",
    "    df_pi[f'{loan_col}_months_since_taken'] = (\n",
    "        taken.groupby(df_pi['Customer_number'], group_keys=False)\n",
    "             .apply(months_since_taken)\n",
    "    )\n",
    "\n",
    "    # Keep only \"in last 4 months\" (else NaN)\n",
    "    df_pi.loc[df_pi[f'{loan_col}_months_since_taken'] > 4, f'{loan_col}_months_since_taken'] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['FactDt', 'Customer_number', 'Business_Volume', 'Gross_wealth',\n",
       "       'Net_Wealth', 'All_Loans', 'House_free_Equity', 'Financial_Assets',\n",
       "       'Investment_Assets', 'RealEstateValue', 'HomeLoan', 'CAR_LOANS',\n",
       "       'BOAT_LOANS', 'Other_loans', 'CustAgeInYears', 'fam_members_adult',\n",
       "       'fam_members', 'CustMobileLogOnPerMth', 'CustNetBankLogOnPerMth',\n",
       "       'IsGeneralMarketingAllowed', 'IsMarketingForEmailAllowed',\n",
       "       'IsMarketingForSmsAllowed', 'IsMarketingForLetterAllowed',\n",
       "       'IsMarketingForPhoneAllowed', 'IsMarketingForEbankAllowed',\n",
       "       'AvgDepositsValueDKK', 'AvgPensionValueDKK', 'AvgHomeFinanceValueDKK',\n",
       "       'AvgOtherLoansValueDKK', 'AvgInvestmentsValueDKK',\n",
       "       'Deposits_Cards_lowest', 'Deposits_ordinary_lowest',\n",
       "       'Creditcard_overdraft_lowest', 'All_Loans_Positive',\n",
       "       'NetWealth_pct_change', 'NetWealth_pct_change_forward',\n",
       "       'NetWealth_abs_change', 'NetWealth_abs_change_forward', 'extreme_jump',\n",
       "       'age_diff', 'first_time_invest', 'BI_Label', 'TTE', 'event_observed',\n",
       "       'anc_y', 'CustGenderCd_M', 'CustGenderCd_N',\n",
       "       'Business_Volume_change_pct', 'Business_Volume_trend_4m',\n",
       "       'Business_Volume_change', 'Net_Wealth_change_pct',\n",
       "       'Net_Wealth_trend_4m', 'Net_Wealth_change',\n",
       "       'Financial_Assets_change_pct', 'Financial_Assets_trend_4m',\n",
       "       'Financial_Assets_change', 'CustMobileLogOnPerMth_diff_1m',\n",
       "       'CustMobileLogOnPerMth_diff_4m_mean', 'CustNetBankLogOnPerMth_diff_1m',\n",
       "       'CustNetBankLogOnPerMth_diff_4m_mean', 'fam_members_diff_1m',\n",
       "       'fam_members_change_dir', 'fam_members_months_since_change',\n",
       "       'HomeLoan_taken_4m', 'HomeLoan_months_since_taken',\n",
       "       'CAR_LOANS_taken_4m', 'CAR_LOANS_months_since_taken'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_pi.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now columns we actually want to use to train the model:\n",
    "\n",
    "columns_to_use = [\n",
    "    'Customer_number', 'FactDt', 'BI_Label', 'event_observed', 'TTE',\n",
    "    'Gross_wealth','Net_Wealth', 'House_free_Equity', 'Financial_Assets',\n",
    "    'RealEstateValue','HomeLoan', 'CAR_LOANS', 'All_Loans',\n",
    "    'BOAT_LOANS', 'Other_loans', 'CustAgeInYears', 'CustGenderCd_M', 'CustGenderCd_N',\n",
    "    'fam_members_adult', 'fam_members', 'CustMobileLogOnPerMth',\n",
    "    'CustNetBankLogOnPerMth', 'IsGeneralMarketingAllowed',\n",
    "    'IsMarketingForEmailAllowed', 'IsMarketingForSmsAllowed',\n",
    "    'IsMarketingForLetterAllowed', 'IsMarketingForPhoneAllowed',\n",
    "    'IsMarketingForEbankAllowed', 'AvgDepositsValueDKK',\n",
    "    'AvgPensionValueDKK', 'AvgHomeFinanceValueDKK', 'AvgOtherLoansValueDKK',\n",
    "    'AvgInvestmentsValueDKK', 'Deposits_Cards_lowest',\n",
    "    'Deposits_ordinary_lowest', 'Creditcard_overdraft_lowest',\n",
    "    'anc_y',  'Business_Volume_change_pct', 'Business_Volume_trend_4m', \n",
    "     'Net_Wealth_change_pct', 'Net_Wealth_trend_4m'\n",
    "    , 'Financial_Assets_change_pct',\n",
    "    'Financial_Assets_trend_4m', 'CustMobileLogOnPerMth_diff_1m',\n",
    "    'CustMobileLogOnPerMth_diff_4m_mean', 'CustNetBankLogOnPerMth_diff_1m',\n",
    "    'CustNetBankLogOnPerMth_diff_4m_mean', \n",
    "     'fam_members_diff_1m', 'fam_members_change_dir',\n",
    "    'fam_members_months_since_change', 'HomeLoan_taken_4m',\n",
    "    'HomeLoan_months_since_taken', 'CAR_LOANS_taken_4m',\n",
    "    'CAR_LOANS_months_since_taken']\n",
    "\n",
    "df_to_train= df_pi[columns_to_use].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Customer_number</th>\n",
       "      <th>FactDt</th>\n",
       "      <th>BI_Label</th>\n",
       "      <th>event_observed</th>\n",
       "      <th>TTE</th>\n",
       "      <th>Gross_wealth</th>\n",
       "      <th>Net_Wealth</th>\n",
       "      <th>House_free_Equity</th>\n",
       "      <th>Financial_Assets</th>\n",
       "      <th>RealEstateValue</th>\n",
       "      <th>...</th>\n",
       "      <th>CustMobileLogOnPerMth_diff_4m_mean</th>\n",
       "      <th>CustNetBankLogOnPerMth_diff_1m</th>\n",
       "      <th>CustNetBankLogOnPerMth_diff_4m_mean</th>\n",
       "      <th>fam_members_diff_1m</th>\n",
       "      <th>fam_members_change_dir</th>\n",
       "      <th>fam_members_months_since_change</th>\n",
       "      <th>HomeLoan_taken_4m</th>\n",
       "      <th>HomeLoan_months_since_taken</th>\n",
       "      <th>CAR_LOANS_taken_4m</th>\n",
       "      <th>CAR_LOANS_months_since_taken</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>000022D8D733FA51200BF5F45C37AED2</td>\n",
       "      <td>2022-01-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.45</td>\n",
       "      <td>13.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000022D8D733FA51200BF5F45C37AED2</td>\n",
       "      <td>2022-02-28</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.45</td>\n",
       "      <td>13.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000022D8D733FA51200BF5F45C37AED2</td>\n",
       "      <td>2022-03-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.45</td>\n",
       "      <td>13.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>000022D8D733FA51200BF5F45C37AED2</td>\n",
       "      <td>2022-04-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>818.45</td>\n",
       "      <td>818.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>818.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>000022D8D733FA51200BF5F45C37AED2</td>\n",
       "      <td>2022-05-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>818.45</td>\n",
       "      <td>818.45</td>\n",
       "      <td>0.00</td>\n",
       "      <td>818.45</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0174CFCBED87171B4F6A651734F836E4</td>\n",
       "      <td>2022-07-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>4364667.34</td>\n",
       "      <td>2971980.95</td>\n",
       "      <td>2407313.61</td>\n",
       "      <td>564667.34</td>\n",
       "      <td>3800000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1356663.84</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0174CFCBED87171B4F6A651734F836E4</td>\n",
       "      <td>2022-08-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>4360875.31</td>\n",
       "      <td>3050521.74</td>\n",
       "      <td>2489646.43</td>\n",
       "      <td>560875.31</td>\n",
       "      <td>3800000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1310353.57</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0174CFCBED87171B4F6A651734F836E4</td>\n",
       "      <td>2022-09-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>4369139.84</td>\n",
       "      <td>3156168.71</td>\n",
       "      <td>2587028.87</td>\n",
       "      <td>569139.84</td>\n",
       "      <td>3800000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1212971.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0174CFCBED87171B4F6A651734F836E4</td>\n",
       "      <td>2022-10-31</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>4378636.00</td>\n",
       "      <td>3102424.29</td>\n",
       "      <td>2523788.29</td>\n",
       "      <td>578636.00</td>\n",
       "      <td>3800000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1212971.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0174CFCBED87171B4F6A651734F836E4</td>\n",
       "      <td>2022-11-30</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>4353584.41</td>\n",
       "      <td>3066565.97</td>\n",
       "      <td>2487981.56</td>\n",
       "      <td>578584.41</td>\n",
       "      <td>3775000.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>-1212971.13</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>70562 rows × 54 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Customer_number     FactDt  BI_Label  event_observed  \\\n",
       "0   000022D8D733FA51200BF5F45C37AED2 2022-01-31         0               0   \n",
       "1   000022D8D733FA51200BF5F45C37AED2 2022-02-28         0               0   \n",
       "2   000022D8D733FA51200BF5F45C37AED2 2022-03-31         0               0   \n",
       "3   000022D8D733FA51200BF5F45C37AED2 2022-04-30         0               0   \n",
       "4   000022D8D733FA51200BF5F45C37AED2 2022-05-31         0               0   \n",
       "..                               ...        ...       ...             ...   \n",
       "6   0174CFCBED87171B4F6A651734F836E4 2022-07-31         0               0   \n",
       "7   0174CFCBED87171B4F6A651734F836E4 2022-08-31         0               0   \n",
       "8   0174CFCBED87171B4F6A651734F836E4 2022-09-30         0               0   \n",
       "9   0174CFCBED87171B4F6A651734F836E4 2022-10-31         0               0   \n",
       "10  0174CFCBED87171B4F6A651734F836E4 2022-11-30         0               0   \n",
       "\n",
       "     TTE  Gross_wealth  Net_Wealth  House_free_Equity  Financial_Assets  \\\n",
       "0   13.0         13.45       13.45               0.00             13.45   \n",
       "1   12.0         13.45       13.45               0.00             13.45   \n",
       "2   11.0         13.45       13.45               0.00             13.45   \n",
       "3   10.0        818.45      818.45               0.00            818.45   \n",
       "4    9.0        818.45      818.45               0.00            818.45   \n",
       "..   ...           ...         ...                ...               ...   \n",
       "6    7.0    4364667.34  2971980.95         2407313.61         564667.34   \n",
       "7    6.0    4360875.31  3050521.74         2489646.43         560875.31   \n",
       "8    5.0    4369139.84  3156168.71         2587028.87         569139.84   \n",
       "9    4.0    4378636.00  3102424.29         2523788.29         578636.00   \n",
       "10   3.0    4353584.41  3066565.97         2487981.56         578584.41   \n",
       "\n",
       "    RealEstateValue  ...  CustMobileLogOnPerMth_diff_4m_mean  \\\n",
       "0               0.0  ...                                 NaN   \n",
       "1               0.0  ...                                 0.0   \n",
       "2               0.0  ...                                 0.0   \n",
       "3               0.0  ...                                 0.0   \n",
       "4               0.0  ...                                 0.0   \n",
       "..              ...  ...                                 ...   \n",
       "6         3800000.0  ...                                 0.0   \n",
       "7         3800000.0  ...                                 0.0   \n",
       "8         3800000.0  ...                                 0.0   \n",
       "9         3800000.0  ...                                 0.0   \n",
       "10        3775000.0  ...                                 0.0   \n",
       "\n",
       "    CustNetBankLogOnPerMth_diff_1m  CustNetBankLogOnPerMth_diff_4m_mean  \\\n",
       "0                              NaN                                  NaN   \n",
       "1                              0.0                                 0.00   \n",
       "2                              0.0                                 0.00   \n",
       "3                              0.0                                 0.00   \n",
       "4                              0.0                                 0.00   \n",
       "..                             ...                                  ...   \n",
       "6                              0.0                                -0.25   \n",
       "7                              0.0                                -0.25   \n",
       "8                              0.0                                -1.00   \n",
       "9                              1.0                                 0.25   \n",
       "10                             3.0                                 1.00   \n",
       "\n",
       "    fam_members_diff_1m  fam_members_change_dir  \\\n",
       "0                   NaN                     NaN   \n",
       "1                   0.0                     0.0   \n",
       "2                   0.0                     0.0   \n",
       "3                   0.0                     0.0   \n",
       "4                   0.0                     0.0   \n",
       "..                  ...                     ...   \n",
       "6                   0.0                     0.0   \n",
       "7                   0.0                     0.0   \n",
       "8                   0.0                     0.0   \n",
       "9                   0.0                     0.0   \n",
       "10                  0.0                     0.0   \n",
       "\n",
       "    fam_members_months_since_change  HomeLoan_taken_4m  \\\n",
       "0                               0.0               0.00   \n",
       "1                               0.0               0.00   \n",
       "2                               0.0               0.00   \n",
       "3                               0.0               0.00   \n",
       "4                               0.0               0.00   \n",
       "..                              ...                ...   \n",
       "6                               0.0        -1356663.84   \n",
       "7                               0.0        -1310353.57   \n",
       "8                               0.0        -1212971.13   \n",
       "9                               0.0        -1212971.13   \n",
       "10                              0.0        -1212971.13   \n",
       "\n",
       "    HomeLoan_months_since_taken  CAR_LOANS_taken_4m  \\\n",
       "0                           0.0                 0.0   \n",
       "1                           0.0                 0.0   \n",
       "2                           0.0                 0.0   \n",
       "3                           0.0                 0.0   \n",
       "4                           0.0                 0.0   \n",
       "..                          ...                 ...   \n",
       "6                           0.0                 0.0   \n",
       "7                           0.0                 0.0   \n",
       "8                           0.0                 0.0   \n",
       "9                           0.0                 0.0   \n",
       "10                          0.0                 0.0   \n",
       "\n",
       "    CAR_LOANS_months_since_taken  \n",
       "0                            0.0  \n",
       "1                            0.0  \n",
       "2                            0.0  \n",
       "3                            0.0  \n",
       "4                            0.0  \n",
       "..                           ...  \n",
       "6                            0.0  \n",
       "7                            0.0  \n",
       "8                            0.0  \n",
       "9                            0.0  \n",
       "10                           0.0  \n",
       "\n",
       "[70562 rows x 54 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_to_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_to_train.to_csv(\"df_to_train.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "eb70d7be6e878a257ee7d39134250d7a4fb9ff25c580e9c4e13f3d7a67e16ecd"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
